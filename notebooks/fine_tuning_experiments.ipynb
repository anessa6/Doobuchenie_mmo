{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80acf660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "lr = 0.005\n",
    "model_name = 'resnet18'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4ff94bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 90, Val: 15, Test: 21\n"
     ]
    }
   ],
   "source": [
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder('../data/split/train', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder('../data/split/val', transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder('../data/split/test', transform=val_test_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "179037b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'resnet18': timm.create_model('resnet18', pretrained=True, num_classes=3),\n",
    "    'efficientnet_b0': timm.create_model('efficientnet_b0', pretrained=True, num_classes=3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ece95e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, model_name, num_unfrozen_layers=0):\n",
    "    # Freeze all parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Unfreeze the FC layer based on model architecture\n",
    "    if 'resnet' in model_name.lower():\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    elif 'efficientnet' in model_name.lower():\n",
    "        for param in model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Optionally unfreeze additional layers\n",
    "    if num_unfrozen_layers > 0:\n",
    "        for param in list(model.parameters())[-num_unfrozen_layers:]:\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef4d33",
   "metadata": {},
   "source": [
    "ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "442c15ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=3, bias=True)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freeze_layers(models['resnet18'], 'resnet18', num_unfrozen_layers=0)\n",
    "models['resnet18'].fc.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d983ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in models['resnet18'].layer4.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ab04c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, train_loader, val_loader, config):\n",
    "    model = model.to(config['device'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        train_loss, train_preds, train_labels = 0.0, [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(config['device']), labels.to(config['device'])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            train_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_acc = accuracy_score(train_labels, train_preds)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_preds, val_labels = 0.0, [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(config['device']), labels.to(config['device'])\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                val_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = accuracy_score(val_labels, val_preds)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Epoch {epoch+1}/{config['epochs']}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Сохранение модели\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    save_path = f\"models/{config['model_name']}_bs{config['batch_size']}_lr{config['lr']}.pth\"\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Модель сохранена: {save_path}\")\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies, val_preds, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "897b78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lr': lr, 'epochs': 10, 'device': device, 'model_name': model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "484d8f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение resnet18 с batch_size=8, lr=0.005\n",
      "Размороженные параметры для resnet18: ['fc.weight', 'fc.bias']\n",
      "Epoch 1/10: Train Loss: 0.9072, Train Acc: 0.5111, Val Loss: 0.5629, Val Acc: 0.6667\n",
      "Epoch 2/10: Train Loss: 0.4570, Train Acc: 0.8889, Val Loss: 0.2446, Val Acc: 1.0000\n",
      "Epoch 3/10: Train Loss: 0.3064, Train Acc: 0.8889, Val Loss: 0.1790, Val Acc: 1.0000\n",
      "Epoch 4/10: Train Loss: 0.2790, Train Acc: 0.8778, Val Loss: 0.1228, Val Acc: 1.0000\n",
      "Epoch 5/10: Train Loss: 0.1795, Train Acc: 0.9556, Val Loss: 0.1055, Val Acc: 1.0000\n",
      "Epoch 6/10: Train Loss: 0.1650, Train Acc: 0.9778, Val Loss: 0.1063, Val Acc: 1.0000\n",
      "Epoch 7/10: Train Loss: 0.2578, Train Acc: 0.9333, Val Loss: 0.0693, Val Acc: 1.0000\n",
      "Epoch 8/10: Train Loss: 0.1209, Train Acc: 0.9889, Val Loss: 0.0589, Val Acc: 1.0000\n",
      "Epoch 9/10: Train Loss: 0.1330, Train Acc: 0.9778, Val Loss: 0.0612, Val Acc: 1.0000\n",
      "Epoch 10/10: Train Loss: 0.1366, Train Acc: 0.9667, Val Loss: 0.0465, Val Acc: 1.0000\n",
      "Модель сохранена: models/resnet18_bs8_lr0.005.pth\n",
      "Обучение resnet18 с batch_size=16, lr=0.005\n",
      "Размороженные параметры для resnet18: ['fc.weight', 'fc.bias']\n",
      "Epoch 1/10: Train Loss: 0.1018, Train Acc: 0.9778, Val Loss: 0.0518, Val Acc: 1.0000\n",
      "Epoch 2/10: Train Loss: 0.0713, Train Acc: 0.9889, Val Loss: 0.0299, Val Acc: 1.0000\n",
      "Epoch 3/10: Train Loss: 0.0696, Train Acc: 0.9889, Val Loss: 0.0261, Val Acc: 1.0000\n",
      "Epoch 4/10: Train Loss: 0.0880, Train Acc: 0.9778, Val Loss: 0.0186, Val Acc: 1.0000\n",
      "Epoch 5/10: Train Loss: 0.0342, Train Acc: 1.0000, Val Loss: 0.0186, Val Acc: 1.0000\n",
      "Epoch 6/10: Train Loss: 0.0422, Train Acc: 0.9889, Val Loss: 0.0162, Val Acc: 1.0000\n",
      "Epoch 7/10: Train Loss: 0.0315, Train Acc: 1.0000, Val Loss: 0.0147, Val Acc: 1.0000\n",
      "Epoch 8/10: Train Loss: 0.0291, Train Acc: 1.0000, Val Loss: 0.0115, Val Acc: 1.0000\n",
      "Epoch 9/10: Train Loss: 0.0602, Train Acc: 0.9889, Val Loss: 0.0097, Val Acc: 1.0000\n",
      "Epoch 10/10: Train Loss: 0.0268, Train Acc: 1.0000, Val Loss: 0.0101, Val Acc: 1.0000\n",
      "Модель сохранена: models/resnet18_bs16_lr0.005.pth\n",
      "Обучение efficientnet_b0 с batch_size=8, lr=0.005\n",
      "Размороженные параметры для efficientnet_b0: ['classifier.weight', 'classifier.bias']\n",
      "Epoch 1/10: Train Loss: 2.2516, Train Acc: 0.5556, Val Loss: 0.8974, Val Acc: 0.6667\n",
      "Epoch 2/10: Train Loss: 1.2332, Train Acc: 0.6889, Val Loss: 0.3206, Val Acc: 0.8000\n",
      "Epoch 3/10: Train Loss: 0.8533, Train Acc: 0.7556, Val Loss: 0.3879, Val Acc: 0.8667\n",
      "Epoch 4/10: Train Loss: 0.5511, Train Acc: 0.7889, Val Loss: 0.3686, Val Acc: 0.8667\n",
      "Epoch 5/10: Train Loss: 0.3052, Train Acc: 0.9111, Val Loss: 0.2357, Val Acc: 0.9333\n",
      "Epoch 6/10: Train Loss: 0.2883, Train Acc: 0.8889, Val Loss: 0.1057, Val Acc: 0.9333\n",
      "Epoch 7/10: Train Loss: 0.4386, Train Acc: 0.9222, Val Loss: 0.0218, Val Acc: 1.0000\n",
      "Epoch 8/10: Train Loss: 0.4187, Train Acc: 0.8333, Val Loss: 0.2359, Val Acc: 0.8667\n",
      "Epoch 9/10: Train Loss: 0.1852, Train Acc: 0.9111, Val Loss: 0.0414, Val Acc: 1.0000\n",
      "Epoch 10/10: Train Loss: 0.3228, Train Acc: 0.8889, Val Loss: 0.1255, Val Acc: 0.9333\n",
      "Модель сохранена: models/efficientnet_b0_bs8_lr0.005.pth\n",
      "Обучение efficientnet_b0 с batch_size=16, lr=0.005\n",
      "Размороженные параметры для efficientnet_b0: ['classifier.weight', 'classifier.bias']\n",
      "Epoch 1/10: Train Loss: 0.1719, Train Acc: 0.9444, Val Loss: 0.0503, Val Acc: 0.9333\n",
      "Epoch 2/10: Train Loss: 0.0574, Train Acc: 0.9778, Val Loss: 0.0585, Val Acc: 0.9333\n",
      "Epoch 3/10: Train Loss: 0.0590, Train Acc: 0.9667, Val Loss: 0.0988, Val Acc: 0.9333\n",
      "Epoch 4/10: Train Loss: 0.0268, Train Acc: 0.9889, Val Loss: 0.1799, Val Acc: 0.9333\n",
      "Epoch 5/10: Train Loss: 0.0799, Train Acc: 0.9556, Val Loss: 0.1565, Val Acc: 0.9333\n",
      "Epoch 6/10: Train Loss: 0.0042, Train Acc: 1.0000, Val Loss: 0.2226, Val Acc: 0.9333\n",
      "Epoch 7/10: Train Loss: 0.1212, Train Acc: 0.9667, Val Loss: 0.1967, Val Acc: 0.9333\n",
      "Epoch 8/10: Train Loss: 0.1027, Train Acc: 0.9778, Val Loss: 0.1637, Val Acc: 0.9333\n",
      "Epoch 9/10: Train Loss: 0.1079, Train Acc: 0.9444, Val Loss: 0.1334, Val Acc: 0.9333\n",
      "Epoch 10/10: Train Loss: 0.0153, Train Acc: 0.9889, Val Loss: 0.1524, Val Acc: 0.9333\n",
      "Модель сохранена: models/efficientnet_b0_bs16_lr0.005.pth\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [8, 16]\n",
    "lrs = [5e-3]\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for bs in batch_sizes:\n",
    "        for lr in lrs:\n",
    "            print(f'Обучение {model_name} с batch_size={bs}, lr={lr}')\n",
    "            train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "            config = {'lr': lr, 'epochs': 10, 'device': device, 'model_name': model_name, 'batch_size': bs}\n",
    "            freeze_layers(model, model_name, num_unfrozen_layers=0)\n",
    "            print(f\"Размороженные параметры для {model_name}:\", [name for name, param in model.named_parameters() if param.requires_grad])\n",
    "            results[f'{model_name}_bs{bs}_lr{lr}'] = train_and_evaluate(model, train_loader, val_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d59e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результаты для rosnet18_bs8_lr0.005 отсутствуют\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Создаем папку для графиков\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "def plot_learning_curves(results, model_name, batch_size, lr):\n",
    "    # Извлекаем результаты для конкретной комбинации\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies, _, _ = results[f'{model_name}_bs{batch_size}_lr{lr}']\n",
    "    \n",
    "    # Создаем график\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # График Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(val_losses, label='Val Loss', marker='s')\n",
    "    plt.title(f'{model_name} (bs={batch_size}, lr={lr}) - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # График Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Acc', marker='o')\n",
    "    plt.plot(val_accuracies, label='Val Acc', marker='s')\n",
    "    plt.title(f'{model_name} (bs={batch_size}, lr={lr}) - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Сохраняем график\n",
    "    save_path = f'plots/{model_name}_bs{batch_size}_lr{lr}.png'\n",
    "    plt.savefig(save_path)\n",
    "    print(f'График сохранен: {save_path}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "bs = 8\n",
    "lr = 0.005\n",
    "model_name = 'resnet18'\n",
    "\n",
    "            \n",
    "if f'{model_name}_bs{bs}_lr{lr}' in results:\n",
    "    plot_learning_curves(results, model_name, bs, lr)\n",
    "else:\n",
    "    print(f'Результаты для {model_name}_bs{bs}_lr{lr} отсутствуют')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "087082dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14084\\2603813617.py:17: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W0226 23:02:29.626000 14084 site-packages\\torch\\onnx\\_internal\\exporter\\_schemas.py:455] Missing annotation for parameter 'input' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0, sampling_ratio: 'int' = -1, aligned: 'bool' = False). Treating as an Input.\n",
      "W0226 23:02:29.627000 14084 site-packages\\torch\\onnx\\_internal\\exporter\\_schemas.py:455] Missing annotation for parameter 'boxes' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0, sampling_ratio: 'int' = -1, aligned: 'bool' = False). Treating as an Input.\n",
      "W0226 23:02:29.629000 14084 site-packages\\torch\\onnx\\_internal\\exporter\\_schemas.py:455] Missing annotation for parameter 'input' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0). Treating as an Input.\n",
      "W0226 23:02:29.630000 14084 site-packages\\torch\\onnx\\_internal\\exporter\\_schemas.py:455] Missing annotation for parameter 'boxes' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0). Treating as an Input.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ResNet([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Python\\pythoncore-3.14-64\\Lib\\copyreg.py:104: FutureWarning: `isinstance(treespec, LeafSpec)` is deprecated, use `isinstance(treespec, TreeSpec) and treespec.is_leaf()` instead.\n",
      "  return cls.__new__(cls, *args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 41 of general pattern rewrite rules.\n",
      "Модель экспортирована в models/resnet18_bs16_lr0.005.onnx\n",
      "ONNX модель проверена успешно\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import onnx\n",
    "import os\n",
    "\n",
    "def export_to_onnx(model_name, model_path, onnx_path, input_shape=(1, 3, 224, 224), device='cpu'):\n",
    "    # Загружаем модель\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=3)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Создаем фиктивный входной тензор\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "\n",
    "    # Экспортируем модель в ONNX\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=18,  # Используем более новую версию opset\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],  # Имя входного тензора\n",
    "        output_names=['output'],  # Имя выходного тензора\n",
    "        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}  # Указываем динамическую ось для batch_size\n",
    "    )\n",
    "    print(f\"Модель экспортирована в {onnx_path}\")\n",
    "\n",
    "    # Проверяем корректность ONNX модели\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(f\"ONNX модель проверена успешно\")\n",
    "\n",
    "# Параметры\n",
    "best_model_name = 'resnet18'\n",
    "best_model_path = 'models/resnet18_bs16_lr0.005.pth'\n",
    "onnx_path = f'models/{best_model_name}_bs16_lr0.005.onnx'\n",
    "\n",
    "# Экспорт\n",
    "os.makedirs('models', exist_ok=True)\n",
    "export_to_onnx(best_model_name, best_model_path, onnx_path, device='cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
